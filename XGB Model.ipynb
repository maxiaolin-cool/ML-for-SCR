{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae1a52a-83dc-44f1-ac68-035052451b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "外层模型训练与评估...\n",
      "\n",
      "外层模型已保存至：xgboost_model_ncv\\xgboost_model.pkl\n",
      "\n",
      "外层模型性能：\n",
      "       Train R2  Test R2  Train RMSE  Test RMSE\n",
      "Value  0.998865  0.77791    0.008845   0.152524\n",
      "\n",
      "开始内层5折交叉验证...\n",
      "\n",
      "正在处理第 1 折...\n",
      "第 1 折完成 - 验证集R2: 0.0832\n",
      "\n",
      "正在处理第 2 折...\n",
      "第 2 折完成 - 验证集R2: 0.0362\n",
      "\n",
      "正在处理第 3 折...\n",
      "第 3 折完成 - 验证集R2: 0.4582\n",
      "\n",
      "正在处理第 4 折...\n",
      "第 4 折完成 - 验证集R2: -0.0051\n",
      "\n",
      "正在处理第 5 折...\n",
      "第 5 折完成 - 验证集R2: 0.2718\n",
      "\n",
      "交叉验证结果汇总：\n",
      "   Train R2   Test R2  Train RMSE  Test RMSE\n",
      "0  0.972181  0.083182    0.047087   0.155161\n",
      "1  0.994045  0.036184    0.015544   0.400615\n",
      "2  0.999504  0.458175    0.006030   0.160132\n",
      "3  0.980205 -0.005097    0.038352   0.216736\n",
      "4  0.997062  0.271756    0.014897   0.171832\n",
      "\n",
      "交叉验证平均性能：\n",
      "Train R2: 0.9886 ± 0.0118\n",
      "Test R2: 0.1688 ± 0.1933\n",
      "Train RMSE: 0.0244 ± 0.0174\n",
      "Test RMSE: 0.2209 ± 0.1034\n",
      "\n",
      "实际值 vs 预测值图已保存至：xgboost_model_ncv\\actual_vs_predicted.png\n",
      "\n",
      "评估结果已保存至 results_summary.txt\n",
      "\n",
      "嵌套交叉验证完成！所有结果保存在目录： xgboost_model_ncv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, mean_squared_error, r2_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ==================== 参数配置 ====================\n",
    "input_path = \"归一化数据-20251120.xlsx\"  # 输入数据路径\n",
    "output_dir = \"xgboost_model_ncv\"     # 输出目录\n",
    "target_column = \"SO2 tolerance\"     # 目标变量列名\n",
    "outer_test_size = 0.2               # 外层测试集比例\n",
    "inner_test_size=0.2                 # 内层测试集比例   \n",
    "random_state = 42                   # 随机种子\n",
    "n_splits = 5                        # 交叉验证折数\n",
    "model_path = os.path.join(output_dir, \"xgboost_model.pkl\")  # 模型保存路径\n",
    "\n",
    "# ==================== 函数定义 ====================\n",
    "def prepare_data(input_path, target_column):\n",
    "    \"\"\"数据加载与预处理\"\"\"\n",
    "    df = pd.read_excel(input_path)\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"目标列 {target_column} 不存在于数据中\")\n",
    "    \n",
    "    y = df[target_column]\n",
    "    X = df.drop(columns=[target_column])\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "    return X[numeric_cols], y\n",
    "\n",
    "def determine_problem_type(y):\n",
    "    \"\"\"自动判断问题类型\"\"\"\n",
    "    if y.nunique() <= 10:  # 分类问题（类别数≤10）\n",
    "        return ('binary:logistic' if y.nunique() == 2 else 'multi:softprob', \n",
    "                \"classification\")\n",
    "    return ('reg:squarederror', \"regression\")\n",
    "\n",
    "def get_model_params(objective, random_state):\n",
    "    \"\"\"获取模型参数\"\"\"\n",
    "    return {\n",
    "        'objective': objective,\n",
    "        'eval_metric': 'logloss' if objective.startswith('binary') else 'rmse',\n",
    "        'eta': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'seed': random_state,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, params, problem_type):\n",
    "    \"\"\"训练模型并返回评估结果\"\"\"\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    ddata_train = xgb.DMatrix(X_train)\n",
    "    ddata_test = xgb.DMatrix(X_test)\n",
    "    \n",
    "    if problem_type == \"classification\":\n",
    "        y_pred_train =np.round(model.predict(ddata_train)) if params['objective'] == 'binary:logistic' else np.argmax(model.predict(ddata_train), axis=1)\n",
    "        y_pred_test =np.round(model.predict(ddata_test)) if params['objective'] == 'binary:logistic' else np.argmax(model.predict(ddata_test), axis=1)\n",
    "        metrics = {\n",
    "            'Train Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "            'Test Accuracy': accuracy_score(y_test, y_pred_test),\n",
    "            'Train F1': f1_score(y_train, y_pred_train, average='macro'),\n",
    "            'Test F1': f1_score(y_test, y_pred_test, average='macro')\n",
    "        }\n",
    "    else:\n",
    "        y_pred_train = model.predict(ddata_train)\n",
    "        y_pred_test = model.predict(ddata_test)\n",
    "        metrics = {\n",
    "            'Train R2': r2_score(y_train, y_pred_train),\n",
    "            'Test R2': r2_score(y_test, y_pred_test),\n",
    "            'Train RMSE': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'Test RMSE': np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        }\n",
    "    return model, metrics\n",
    "def plot_feature_importance(model, output_dir):\n",
    "    \"\"\"\n",
    "    绘制特征重要性图（使用自定义颜色方案）\n",
    "    \n",
    "    参数:\n",
    "        model: 训练好的XGBoost模型\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    # 自定义颜色方案（根据用户提供的颜色）\n",
    "    custom_colors = {\n",
    "        'EN.': '#82bbf0', \n",
    "        'P.Tim. ':'#dff1ff', \n",
    "        'S.A.': '#FDB3CC', \n",
    "        'GHSV': '#ff78A8', \n",
    "        'I.R.': '#82bbf0', \n",
    "        'I.E.': '#82bbf0', \n",
    "        'P.D.': '#FDB3CC',\n",
    "        'H2O': '#ff78A8', \n",
    "        'P.TEM.': '#dff1ff', \n",
    "        'M.P.': '#82bbf0', \n",
    "        'T.C.': '#82bbf0', \n",
    "        'P.V.': '#FDB3CC', \n",
    "        'C.Tem.': '#FDB3CC',\n",
    "        'Density': '#82bbf0',\n",
    "        'NH3': '#ff78A8', \n",
    "        'SO2': '#dff1ff', \n",
    "        'C.Tim.': '#FDB3CC', \n",
    "        'O2': '#ff78A8', \n",
    "        'NO': '#ff78A8'\n",
    "    }\n",
    "    \n",
    "    # 设置全局字体样式\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    \n",
    "    # 设置图形大小和边缘距离\n",
    "    fig, ax = plt.subplots(figsize=(14, 10), facecolor='none')\n",
    "    plt.subplots_adjust(left=0.2, right=0.95, top=0.9, bottom=0.1)\n",
    "    ax.grid(False)\n",
    "    ax.set_facecolor('white')  \n",
    "    \n",
    "    # 获取特征重要性数据\n",
    "    importance = model.get_score(importance_type='weight')\n",
    "    importance = sorted(importance.items(), key=lambda x: x[1], reverse=False)\n",
    "    feature_names = [x[0] for x in importance]\n",
    "    feature_imp = [x[1] for x in importance]\n",
    "    \n",
    "    # 为每个特征分配颜色（如果特征未在自定义颜色中定义，使用默认颜色）\n",
    "    colors = [custom_colors.get(feature, '#1f77b4') for feature in feature_names]\n",
    "    \n",
    "    # 绘制水平条形图\n",
    "    bars = ax.barh(\n",
    "        range(len(feature_names)), \n",
    "        feature_imp, \n",
    "        height=0.8,  # 调整柱形宽度\n",
    "        color=colors,  # 使用自定义颜色\n",
    "    )\n",
    "    \n",
    "    # 设置y轴刻度\n",
    "    ax.set_yticks(range(len(feature_names)))\n",
    "    ax.set_yticklabels(feature_names)\n",
    "    \n",
    "    # 设置x轴标签\n",
    "    plt.xlabel(\n",
    "        \"Importance\",\n",
    "        fontdict={\n",
    "            'fontname': 'Arial',\n",
    "            'fontsize': 24,\n",
    "            'fontweight': 'bold'\n",
    "        },\n",
    "        labelpad=10  # 标签与轴的距离\n",
    "    )\n",
    "    \n",
    "    # 设置y轴标签\n",
    "    plt.ylabel(\n",
    "        ' ',\n",
    "        fontdict={\n",
    "            'fontname': 'Arial',\n",
    "            'fontsize': 20,\n",
    "            'fontweight': 'bold'\n",
    "        },\n",
    "        labelpad=10  # 标签与轴的距离\n",
    "    )\n",
    "    \n",
    "    # 设置坐标轴刻度字体\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontname('Arial')\n",
    "        label.set_fontsize(20)\n",
    "    \n",
    "    # 保留所有边框并设置样式\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(2.5)  # 加粗边框线\n",
    "        spine.set_color('black')  # 设置边框颜色\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(\n",
    "            width + max(feature_imp)*0.01,  # 位置微调\n",
    "            bar.get_y() + bar.get_height()/2,\n",
    "            f'{width:.1f}',\n",
    "            ha='left',\n",
    "            va='center',\n",
    "            fontname='Arial',\n",
    "            fontsize=18,\n",
    "            color='black'  # 确保文字颜色清晰可见\n",
    "        )\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.savefig(\n",
    "        os.path.join(output_dir, \"feature_importance.png\"), \n",
    "        dpi=300, \n",
    "        bbox_inches='tight',\n",
    "        transparent=False\n",
    "    )\n",
    "    plt.close()\n",
    "    \n",
    "def plot_actual_vs_predicted(X_train, y_train, X_test, y_test, model, output_dir):\n",
    "    \"\"\"绘制实际值 vs 预测值图（回归问题）\"\"\"\n",
    "    # 设置全局字体样式\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    \n",
    "    d_train = xgb.DMatrix(X_train)\n",
    "    pp_tr = model.predict(d_train)\n",
    "    d_test = xgb.DMatrix(X_test)\n",
    "    y_predicted = model.predict(d_test)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    g = sns.JointGrid(x=y_test, y=y_predicted, height=8, space=0)\n",
    "\n",
    "   \n",
    "    g.set_axis_labels(\"Actual value\", \"Predicted value\", fontsize =10, fontname = 'Arial')\n",
    "    sns.scatterplot(x=y_train, y=pp_tr, s=100, color='#DB7987', ax=g.ax_joint, label='Training')\n",
    "    sns.scatterplot(x=y_test, y=y_predicted, s=100, color='#82BBF0', ax=g.ax_joint, label='Testing')\n",
    "    sns.regplot(x=y_test, y=y_predicted, ax=g.ax_joint, scatter=False, color='gray')\n",
    "       \n",
    "    # 调整坐标轴刻度标签样式\n",
    "    for ax in [g.ax_joint, g.ax_marg_x, g.ax_marg_y]:\n",
    "        ax.tick_params(\n",
    "            axis='both', \n",
    "            which='major', \n",
    "            labelsize=28,      # 刻度标签大小\n",
    "            colors='black',   # 刻度标签颜色\n",
    "            width=3,\n",
    "            length=8\n",
    "        )\n",
    "    # 设置图例样式\n",
    "    g.ax_joint.legend(\n",
    "        title_fontsize=28,      # 标题字体大小\n",
    "        fontsize=28,           # 项目字体大小\n",
    "        frameon=False,          # 显示边框\n",
    "        framealpha=1,        # 边框透明度\n",
    "        edgecolor='white',   # 边框颜色\n",
    "        facecolor='white'      # 背景颜色\n",
    "        \n",
    "    )\n",
    "     # 主图边框（闭合，线宽3）\n",
    "    for spine in g.ax_joint.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor('#333333')\n",
    "        spine.set_linewidth(2.5)\n",
    "    \n",
    "    # 计算实际值和预测值的全局范围\n",
    "    all_values = np.concatenate([y_train, y_test, pp_tr, y_predicted])\n",
    "    min_val = np.min(all_values)\n",
    "    max_val = np.max(all_values)\n",
    "    buffer = (max_val - min_val) * 0.15  # 增加缓冲区，确保边缘数据有足够空间\n",
    "    \n",
    "    # 设置主图坐标范围\n",
    "    g.ax_joint.set_xlim(min_val - buffer, max_val + buffer)\n",
    "    g.ax_joint.set_ylim(min_val - buffer, max_val + buffer)\n",
    "    \n",
    "    # 绘制理想预测线\n",
    "    g.ax_joint.plot([min_val, max_val], [min_val, max_val], '--', color='gray', alpha=0.5)\n",
    "    \n",
    "    # 优化边缘分布的面积图\n",
    "    # X轴面积图 - 使用更合适的带宽和范围\n",
    "    sns.kdeplot(\n",
    "        x=y_train, ax=g.ax_marg_x, color='#DB7987', alpha=0.5,\n",
    "        fill=True, linewidth=0, label='Training', bw_adjust=1.5,\n",
    "        clip=(min_val - buffer, max_val + buffer)\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        x=y_test, ax=g.ax_marg_x, color='#82BBF0', alpha=0.5,\n",
    "        fill=True, linewidth=0, label='Testing', bw_adjust=1.5,\n",
    "        clip=(min_val - buffer, max_val + buffer)\n",
    "    )\n",
    "    \n",
    "    # y轴面积图 - 使用更合适的带宽和范围\n",
    "    sns.kdeplot(\n",
    "        y=pp_tr, ax=g.ax_marg_y, color='#DB7987', alpha=0.5,\n",
    "        fill=True, linewidth=0, label='Training', bw_adjust=1.5,\n",
    "        clip=(min_val - buffer, max_val + buffer)\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        y=y_predicted, ax=g.ax_marg_y, color='#82BBF0', alpha=0.5,\n",
    "        fill=True, linewidth=0, label='Testing', bw_adjust=1.5,\n",
    "        clip=(min_val - buffer, max_val + buffer)\n",
    "    )\n",
    "    \n",
    "    # 隐藏边缘分布的图例\n",
    "    legend_x = g.ax_marg_x.legend()\n",
    "    legend_x.set_visible(False)\n",
    "    legend_y = g.ax_marg_y.legend()\n",
    "    legend_y.set_visible(False)\n",
    "    \n",
    "    # 调整边缘分布坐标轴粗细\n",
    "    for ax in [g.ax_marg_x, g.ax_marg_y]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(1)\n",
    "    \n",
    "    # 确保边缘分布与主图坐标范围一致\n",
    "    g.ax_marg_x.set_xlim(g.ax_joint.get_xlim())\n",
    "    g.ax_marg_y.set_ylim(g.ax_joint.get_ylim())\n",
    "    \n",
    "    # 关键修改：在所有绘图操作完成后设置轴标签\n",
    "    g.ax_joint.set_xlabel(\"Actual value\", fontsize=32, fontname='Arial', fontweight='bold')\n",
    "    g.ax_joint.set_ylabel(\"Predicted value\", fontsize=32, fontname='Arial', fontweight='bold')\n",
    "    \n",
    "    # 调整整体布局，确保有足够空间显示面积图\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.12, right=0.95)\n",
    "    \n",
    "    # 保存图像\n",
    "    plot_path = os.path.join(output_dir, \"actual_vs_predicted.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return plot_path\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "def main():\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. 数据准备\n",
    "    X, y = prepare_data(input_path, target_column)\n",
    "    objective, problem_type = determine_problem_type(y)\n",
    "    params = get_model_params(objective, random_state)\n",
    "    \n",
    "    # 2. 外层数据划分\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=outer_test_size, random_state=random_state)\n",
    "    \n",
    "    # 3. 外层模型训练与评估\n",
    "    print(\"外层模型训练与评估...\")\n",
    "    outer_model, outer_metrics = train_and_evaluate(\n",
    "        X_train, y_train, X_test, y_test, params, problem_type)\n",
    "    joblib.dump(outer_model, model_path)\n",
    "    print(f\"\\n外层模型已保存至：{model_path}\")\n",
    "    \n",
    "    # 打印外层评估结果\n",
    "    print(\"\\n外层模型性能：\")\n",
    "    print(pd.DataFrame([outer_metrics], index=['Value']))\n",
    "    \n",
    "    # 4. 内层5折交叉验证\n",
    "    print(f\"\\n开始内层{n_splits}折交叉验证...\")\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    cv_metrics = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "        print(f\"\\n正在处理第 {fold} 折...\")\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model, metrics = train_and_evaluate(X_tr, y_tr, X_val, y_val, params, problem_type)\n",
    "        cv_metrics.append(metrics)\n",
    "        print(f\"第 {fold} 折完成 - 验证集R2: {metrics.get('Test R2', metrics.get('Test Accuracy')):.4f}\")\n",
    "    \n",
    "    # 5. 交叉验证结果分析\n",
    "    cv_results = pd.DataFrame(cv_metrics)\n",
    "    print(\"\\n交叉验证结果汇总：\")\n",
    "    print(cv_results)\n",
    "    \n",
    "    mean_metrics = cv_results.mean().to_dict()\n",
    "    std_metrics = cv_results.std().to_dict()\n",
    "    \n",
    "    print(\"\\n交叉验证平均性能：\")\n",
    "    for metric in mean_metrics:\n",
    "        print(f\"{metric}: {mean_metrics[metric]:.4f} ± {std_metrics[metric]:.4f}\")\n",
    "    \n",
    "    # 6. 可视化与结果保存\n",
    "    plot_feature_importance(outer_model, output_dir)\n",
    "    \n",
    "    if problem_type == \"regression\":\n",
    "        plot_path = plot_actual_vs_predicted(X_train, y_train, X_test, y_test, \n",
    "                                           outer_model, output_dir)\n",
    "        print(f\"\\n实际值 vs 预测值图已保存至：{plot_path}\")\n",
    "    \n",
    "    # 7. 保存评估结果\n",
    "    results = {\n",
    "        'outer_test_r2': outer_metrics.get('Test R2', outer_metrics.get('Test Accuracy')),\n",
    "        'cv_mean_r2': mean_metrics.get('Test R2', mean_metrics.get('Test Accuracy')),\n",
    "        'cv_std_r2': std_metrics.get('Test R2', std_metrics.get('Test Accuracy'))\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"results_summary.txt\"), 'w') as f:\n",
    "        f.write(\"模型评估结果汇总:\\n\")\n",
    "        f.write(f\"外层测试集R2: {results['outer_test_r2']:.4f}\\n\")\n",
    "        f.write(f\"交叉验证平均R2: {results['cv_mean_r2']:.4f} ± {results['cv_std_r2']:.4f}\\n\")\n",
    "    \n",
    "    print(\"\\n评估结果已保存至 results_summary.txt\")\n",
    "    print(\"\\n嵌套交叉验证完成！所有结果保存在目录：\", output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5e07974-dedb-423b-a64d-befb04b529ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and model...\n",
      "Preparing data for SHAP analysis (first 200 samples)...\n",
      "Calculating SHAP values...\n",
      "Generating SHAP plots...\n",
      "Generating Waterfall plots...\n",
      "\n",
      "SHAP analysis completed!\n",
      "Results saved to: shap_analysis\n",
      "Analysis was performed on the first 200 samples.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# ==================== 参数配置 ====================\n",
    "model_path = \"xgboost_model_ncv/xgboost_model.pkl\"  # 模型路径\n",
    "input_path = \"归一化数据-20251120.xlsx\"                      # 输入数据路径\n",
    "output_dir = \"shap_analysis\"                       # 输出目录\n",
    "target_column = \"SO2 tolerance\"                   # 目标变量列名\n",
    "random_state = 42                                 # 随机种子\n",
    "sample_size = 100                                 # 指定分析的样本数量\n",
    "\n",
    "\n",
    "# ==================== 函数定义 ====================\n",
    "def load_data_and_model():\n",
    "    \"\"\"加载数据和模型\"\"\"\n",
    "    model = joblib.load(model_path)\n",
    "    df = pd.read_excel(input_path)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "    return X[numeric_cols], y, model\n",
    "\n",
    "def prepare_shap_data(X, y):\n",
    "    \"\"\"准备SHAP分析数据，只选择前N条记录\"\"\"\n",
    "    # 使用 .iloc[:n] 来获取前n条数据\n",
    "    return X.iloc[:sample_size]\n",
    "\n",
    "def plot_shap_summary(shap_values, X, output_dir):\n",
    "    \"\"\"绘制SHAP摘要图\"\"\"\n",
    "    plt.figure(figsize=(14, 10), facecolor='white')\n",
    "    \n",
    "    # 计算合理的x轴范围\n",
    "    max_shap = max(abs(shap_values.min()), abs(shap_values.max()))\n",
    "    xlim = (-max_shap * 1.1, max_shap * 1.1)  # 使用数据本身的范围，而不是固定值\n",
    "    \n",
    "    shap.summary_plot(shap_values, X, show=False, plot_size=None)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xlim(xlim)  # 设置对称的x轴范围\n",
    "    \n",
    "    # 设置标题样式\n",
    "    plt.title(\" \",\n",
    "              fontsize=26,\n",
    "              pad=20,\n",
    "              fontname='Arial',\n",
    "              fontweight='bold')\n",
    "\n",
    "    # ===== 坐标轴标签设置 =====\n",
    "    ax.set_xlabel(\"SHAP value\",\n",
    "                  fontsize=26,\n",
    "                  fontname='Arial',\n",
    "                  fontweight='bold',\n",
    "                  labelpad=10)\n",
    "\n",
    "    ax.set_ylabel(\" \",\n",
    "                  fontsize=22,\n",
    "                  fontname='Arial',\n",
    "                  fontweight='bold',\n",
    "                  labelpad=10)\n",
    "\n",
    "    # ===== 刻度标签设置 =====\n",
    "    ax.tick_params(axis='x',\n",
    "                   which='both',\n",
    "                   labelsize=22,\n",
    "                   width=3,\n",
    "                   length=8,\n",
    "                   direction='out')\n",
    "\n",
    "    ax.tick_params(axis='y',\n",
    "                   which='both',\n",
    "                   labelsize=22,\n",
    "                   width=3,\n",
    "                   length=8,\n",
    "                   direction='out')\n",
    "\n",
    "    # 设置坐标轴样式\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    \n",
    "    # 保存图形\n",
    "    plot_path = os.path.join(output_dir, \"shap_summary.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "    return plot_path\n",
    "\n",
    "def plot_shap_bar(shap_values, X, output_dir):\n",
    "    \"\"\"绘制SHAP条形图\"\"\"\n",
    "    plt.figure(figsize=(12, 8), facecolor='white')\n",
    "    \n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # 调整边距\n",
    "    plt.subplots_adjust(left=0.3, right=0.95)\n",
    "    \n",
    "    # 设置坐标轴样式\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(3)\n",
    "    \n",
    "    plot_path = os.path.join(output_dir, \"shap_bar.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "    return plot_path\n",
    "\n",
    "def plot_shap_dependence(shap_values, X, output_dir):\n",
    "    \"\"\"绘制SHAP依赖图\"\"\"\n",
    "    os.makedirs(os.path.join(output_dir, \"dependence_plots\"), exist_ok=True)\n",
    "    plot_paths = []\n",
    "    \n",
    "    for feature in X.columns:\n",
    "        plt.figure(figsize=(10, 6), facecolor='white')\n",
    "        shap.dependence_plot(feature, shap_values, X, show=False)\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        ax.grid(False)\n",
    "        ax.set_facecolor('white')\n",
    "        # 设置坐标轴样式\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(True)\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        ax.spines['bottom'].set_linewidth(3)\n",
    "        \n",
    "        plot_path = os.path.join(output_dir, \"dependence_plots\", f\"shap_dependence_{feature}.png\")\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight', transparent=True)\n",
    "        plt.close()\n",
    "        plot_paths.append(plot_path)\n",
    "        \n",
    "    \n",
    "    return plot_paths\n",
    "\n",
    "def plot_shap_waterfall(explainer, shap_values, X_sample, sample_index, output_dir):\n",
    "    \"\"\"绘制SHAP瀑布图\"\"\"\n",
    "    os.makedirs(os.path.join(output_dir, \"waterfall_plots\"), exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 10), facecolor='white')\n",
    "    \n",
    "    expected_value = explainer.expected_value\n",
    "    if isinstance(expected_value, list):\n",
    "        expected_value = expected_value[0]\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        shap_vals = shap_values[0]\n",
    "    else:\n",
    "        shap_vals = shap_values\n",
    "    \n",
    "    # 检查样本索引是否有效\n",
    "    if sample_index >= len(X_sample):\n",
    "        print(f\"Warning: Sample index {sample_index} out of range, using last sample\")\n",
    "        sample_index = len(X_sample) - 1\n",
    "    \n",
    "    # 生成瀑布图\n",
    "    shap.plots.waterfall(\n",
    "        shap.Explanation(\n",
    "            values=shap_vals[sample_index],\n",
    "            base_values=expected_value,\n",
    "            data=X_sample.iloc[sample_index],\n",
    "            feature_names=X_sample.columns.tolist()\n",
    "        ),\n",
    "        show=False,\n",
    "        max_display=10  # 限制显示的特征数量\n",
    "    )\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # 设置字体样式\n",
    "    font_props = {\n",
    "        'family': 'Arial',  # 字体类型\n",
    "        'weight': 'bold',   # 字体加粗\n",
    "        'size': 14          # 字体大小\n",
    "    }\n",
    "    \n",
    "    # 设置坐标轴标签样式\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontdict=font_props)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontdict=font_props)\n",
    "    \n",
    "    # 设置刻度标签样式\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "        label.set_fontname('Arial')\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "        label.set_fontname('Arial')\n",
    "    \n",
    "    # 设置标题样式（如果有）\n",
    "    if ax.get_title():\n",
    "        ax.set_title(ax.get_title(), fontdict={\n",
    "            'fontsize': 14,\n",
    "            'fontweight': 'bold',\n",
    "            'fontname': 'Arial'\n",
    "        })\n",
    "    \n",
    "    # 设置其他文本元素的样式（如特征名称等）\n",
    "    for text in ax.texts:\n",
    "        text.set_fontweight('bold')\n",
    "        text.set_fontname('Arial')\n",
    "        text.set_fontsize(14)\n",
    "\n",
    "    # 调整边距\n",
    "    plt.subplots_adjust(left=0.4, right=0.9)\n",
    "\n",
    "    # 设置坐标轴样式\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['top'].set_color('black')\n",
    "    ax.spines['top'].set_linewidth(2)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['right'].set_color('black')\n",
    "    ax.spines['right'].set_linewidth(2)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['bottom'].set_linewidth(3)\n",
    "\n",
    "    plot_path = os.path.join(output_dir, \"waterfall_plots\", f\"shap_waterfall_{sample_index}.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "    return plot_path\n",
    "\n",
    "def main():\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Loading data and model...\")\n",
    "    X, y, model = load_data_and_model()\n",
    "    \n",
    "    print(f\"Preparing data for SHAP analysis (first {sample_size} samples)...\")\n",
    "    X_shap = prepare_shap_data(X, y)\n",
    "    \n",
    "    print(\"Calculating SHAP values...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_shap)\n",
    "    \n",
    "    print(\"Generating SHAP plots...\")\n",
    "    summary_path = plot_shap_summary(shap_values, X_shap, output_dir)\n",
    "    bar_path = plot_shap_bar(shap_values, X_shap, output_dir)\n",
    "    dependence_paths = plot_shap_dependence(shap_values, X_shap, output_dir)\n",
    "    \n",
    "    print(\"Generating Waterfall plots...\")\n",
    "    waterfall_paths = []\n",
    "    # 确保选择的样本索引在新的、更小的数据集范围内\n",
    "    for i in [0, min(5, len(X_shap)-1), min(188, len(X_shap)-1)]:\n",
    "        try:\n",
    "            path = plot_shap_waterfall(explainer, shap_values, X_shap, i, output_dir)\n",
    "            waterfall_paths.append(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating waterfall plot for sample {i}: {str(e)}\")\n",
    "    \n",
    "    # 保存SHAP值\n",
    "    pd.DataFrame(shap_values, columns=X_shap.columns).to_csv(\n",
    "        os.path.join(output_dir, \"shap_values.csv\"), index=False)\n",
    "    \n",
    "    print(\"\\nSHAP analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}\")\n",
    "    print(f\"Analysis was performed on the first {len(X_shap)} samples.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b498bec9-52e0-4ab6-9592-92614cf54c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved force plot for sample 0 to: shap_force_analysis\\force_plot_sample_0.png\n",
      "Saved force plot for sample 5 to: shap_force_analysis\\force_plot_sample_5.png\n",
      "Saved force plot for sample 188 to: shap_force_analysis\\force_plot_sample_188.png\n",
      "All SHAP force plots generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# ==================== Parameter Configuration ====================\n",
    "MODEL_PATH = \"xgboost_model_ncv/xgboost_model.pkl\"  # Model path\n",
    "DATA_PATH = \"归一化数据-20251120 -去除前两列.xlsx\"                  # Data path\n",
    "OUTPUT_DIR = \"shap_force_analysis\"                  # Output directory\n",
    "TARGET_COL = \"SO2 tolerance\"                       # Target column name\n",
    "SAMPLE_INDICES = [0, 5, 188]                       # Sample indices to analyze\n",
    "DPI = 300                                          # Output resolution\n",
    "CONTRIBUTION_THRESHOLD = 0.1\n",
    "FONT = {'family': 'Arial', 'weight': 'bold', 'size': 10}  # Font settings\n",
    "\n",
    "# ==================== Initialization ====================\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Set global font settings\n",
    "rcParams['font.family'] = FONT['family']\n",
    "rcParams['font.weight'] = FONT['weight']\n",
    "rcParams['font.size'] = FONT['size']\n",
    "rcParams['axes.labelweight'] = 'bold'\n",
    "rcParams['axes.titleweight'] = 'bold'\n",
    "\n",
    "# ==================== Load Model and Data ====================\n",
    "# Load trained model\n",
    "model = joblib.load(MODEL_PATH)\n",
    "\n",
    "# Read data\n",
    "data = pd.read_excel(DATA_PATH)\n",
    "X = data.drop(columns=[TARGET_COL])  # Feature data\n",
    "y = data[TARGET_COL]  # Target variable\n",
    "\n",
    "# ==================== SHAP Analysis ====================\n",
    "# Create SHAP explainer\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# ==================== Generate and Save Force Plots ====================\n",
    "for idx in SAMPLE_INDICES:\n",
    "    if idx >= len(X):\n",
    "        print(f\"Warning: Sample index {idx} out of range, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Create figure with specified size\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Format feature names to display three decimal places\n",
    "    feature_names = X.columns.tolist()\n",
    "    formatted_features = []\n",
    "    for i, feat in enumerate(feature_names):\n",
    "        val = X.iloc[idx, i]\n",
    "        formatted_val = f\"{val:.3f}\"  # Format to three decimal places\n",
    "        formatted_features.append(f\"{feat} = {formatted_val}\")\n",
    "    \n",
    "    # Generate force plot with formatted feature names\n",
    "    force_plot = shap.plots.force(\n",
    "        explainer.expected_value,\n",
    "        shap_values.values[idx, :],\n",
    "        features=X.iloc[idx, :],\n",
    "        feature_names=formatted_features,  # Use formatted feature names\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    plt.title(f\"SHAP Force Plot - Sample {idx}\", fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"Feature value impact on model output\", fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"force_plot_sample_{idx}.png\")\n",
    "    plt.savefig(output_path, dpi=DPI, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved force plot for sample {idx} to: {output_path}\")\n",
    "\n",
    "print(\"All SHAP force plots generated successfully!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b400da2-d2dc-46cf-969d-9354d3f9edc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始ICE分析...\n",
      "分析完成，结果保存在: ice_analysis_results\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# ==================== 参数配置 ====================\n",
    "model_path = \"xgboost_model_ncv/xgboost_model.pkl\"\n",
    "input_path = \"归一化数据-20251120.xlsx\"\n",
    "output_dir = \"ice_analysis_results\"\n",
    "target_column = \"SO2 tolerance\"\n",
    "\n",
    "# 图表样式参数\n",
    "figsize = (17, 14)\n",
    "title_font = {'family': 'Arial', 'size': 18, 'weight': 'bold'}\n",
    "label_font = {'family': 'Arial', 'size': 40, 'weight': 'bold'}\n",
    "tick_font = {'family': 'Arial', 'size': 36, 'weight': 'bold'}\n",
    "legend_font = {'family': 'Arial', 'size': 36, 'weight': 'bold'}\n",
    "\n",
    "line_alpha = 0.3\n",
    "line_color = '#80AAF3'\n",
    "line_width = 3\n",
    "\n",
    "avg_line_color = '#d62728'\n",
    "avg_line_width = 3\n",
    "\n",
    "border_width = 4\n",
    "border_color = 'black'\n",
    "\n",
    "tick_width = 3\n",
    "tick_length = 8\n",
    "\n",
    "dpi = 300\n",
    "\n",
    "# ==================== 函数定义 ====================\n",
    "def load_data_and_model():\n",
    "    \"\"\"加载数据和模型\"\"\"\n",
    "    df = pd.read_excel(input_path)\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"目标列 {target_column} 不存在于数据中\")\n",
    "    \n",
    "    X = df.drop(columns=[target_column]).select_dtypes(include=['number'])\n",
    "    model = joblib.load(model_path)\n",
    "    return X, model\n",
    "\n",
    "def plot_ice_analysis():\n",
    "    \"\"\"执行ICE分析并绘制图表\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    X, model = load_data_and_model()\n",
    "    \n",
    "    for feature in X.columns:\n",
    "        fig = plt.figure(figsize=figsize, facecolor='white')\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # 设置背景为白色（移除透明设置）\n",
    "        fig.patch.set_facecolor('white')\n",
    "        ax.set_facecolor('white')\n",
    "        \n",
    "        grid_values = np.linspace(X[feature].min(), X[feature].max(), 100)\n",
    "        ice_lines = []\n",
    "        \n",
    "        for _, sample in X.iterrows():\n",
    "            X_ice = pd.DataFrame([sample.values]*len(grid_values), columns=X.columns)\n",
    "            X_ice[feature] = grid_values\n",
    "            \n",
    "            preds = model.predict(xgb.DMatrix(X_ice))\n",
    "            ice_lines.append(preds)\n",
    "            plt.plot(grid_values, preds, color=line_color, alpha=line_alpha, linewidth=line_width)\n",
    "        \n",
    "        # 绘制平均线\n",
    "        plt.plot(grid_values, np.mean(ice_lines, axis=0), \n",
    "                color=avg_line_color, linewidth=avg_line_width, label='Average')\n",
    "        \n",
    "        # 设置标题和标签\n",
    "        plt.title(f'ICE Plot for {feature}', fontdict=title_font, pad=20)\n",
    "        plt.xlabel(feature, fontdict=label_font, labelpad=10)\n",
    "        plt.ylabel('Predicted value', fontdict=label_font, labelpad=10)\n",
    "        \n",
    "        # 设置刻度\n",
    "        ax.tick_params(axis='both', which='major', \n",
    "                      labelsize=tick_font['size'],\n",
    "                      width=tick_width,\n",
    "                      length=tick_length)\n",
    "        \n",
    "        # 设置刻度标签字体\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_fontproperties(tick_font)\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_fontproperties(tick_font)\n",
    "        \n",
    "        # 设置图例\n",
    "        legend = plt.legend(prop=legend_font, frameon=False, loc='upper right')\n",
    "        for text in legend.get_texts():\n",
    "            text.set_weight('bold')\n",
    "        \n",
    "        # 设置边框\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(border_width)\n",
    "            spine.set_color(border_color)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"ice_{feature}.png\"), \n",
    "                   dpi=dpi, bbox_inches='tight')  # 移除transparent=True\n",
    "        plt.close()\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"开始ICE分析...\")\n",
    "    plot_ice_analysis()\n",
    "    print(f\"分析完成，结果保存在: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d185bf81-70d4-4b6d-9a8b-73f96e03b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始生成 'EN.' 在区间 (0.7, 0.8) 内的ICE分析图 (图中不显示置信区间)...\n",
      "正在计算每个样本的ICE曲线...\n",
      "已处理 50 个样本...\n",
      "已处理 100 个样本...\n",
      "已处理 150 个样本...\n",
      "已处理 200 个样本...\n",
      "在区间 (0.7, 0.8) 内找到 416 个数据点，准备进行拟合...\n",
      "数据已导出至: ice_smooth_results\\ice_focused_on_0.7_0.8_EN__with_ci_data.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:161: UserWarning: First parameter to grid() is false, but line properties are supplied. The grid will be enabled.\n",
      "  ax.grid(False, linestyle=':', alpha=0.6)\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 26512 (\\N{CJK UNIFIED IDEOGRAPH-6790}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 32858 (\\N{CJK UNIFIED IDEOGRAPH-805A}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 28966 (\\N{CJK UNIFIED IDEOGRAPH-7126}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 21306 (\\N{CJK UNIFIED IDEOGRAPH-533A}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 38388 (\\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 21407 (\\N{CJK UNIFIED IDEOGRAPH-539F}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 22987 (\\N{CJK UNIFIED IDEOGRAPH-59CB}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 24179 (\\N{CJK UNIFIED IDEOGRAPH-5E73}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 38454 (\\N{CJK UNIFIED IDEOGRAPH-9636}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 22810 (\\N{CJK UNIFIED IDEOGRAPH-591A}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 39033 (\\N{CJK UNIFIED IDEOGRAPH-9879}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 24335 (\\N{CJK UNIFIED IDEOGRAPH-5F0F}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 25311 (\\N{CJK UNIFIED IDEOGRAPH-62DF}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:166: UserWarning: Glyph 21512 (\\N{CJK UNIFIED IDEOGRAPH-5408}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 26512 (\\N{CJK UNIFIED IDEOGRAPH-6790}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 32858 (\\N{CJK UNIFIED IDEOGRAPH-805A}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 28966 (\\N{CJK UNIFIED IDEOGRAPH-7126}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 21306 (\\N{CJK UNIFIED IDEOGRAPH-533A}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 38388 (\\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 21407 (\\N{CJK UNIFIED IDEOGRAPH-539F}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 22987 (\\N{CJK UNIFIED IDEOGRAPH-59CB}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 24179 (\\N{CJK UNIFIED IDEOGRAPH-5E73}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 38454 (\\N{CJK UNIFIED IDEOGRAPH-9636}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 22810 (\\N{CJK UNIFIED IDEOGRAPH-591A}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 39033 (\\N{CJK UNIFIED IDEOGRAPH-9879}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 24335 (\\N{CJK UNIFIED IDEOGRAPH-5F0F}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 25311 (\\N{CJK UNIFIED IDEOGRAPH-62DF}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\4047348588.py:167: UserWarning: Glyph 21512 (\\N{CJK UNIFIED IDEOGRAPH-5408}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图表已保存至: ice_smooth_results\\ice_focused_on_0.7_0.8_EN__no_ci_plot.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# ==================== 参数配置 ====================\n",
    "model_path = \"xgboost_model_ncv/xgboost_model.pkl\"\n",
    "input_path = \"归一化数据-20251120.xlsx\"\n",
    "output_dir = \"ice_smooth_results\"\n",
    "target_column = \"SO2 tolerance\"\n",
    "feature_to_plot = \"EN.\"\n",
    "\n",
    "# 感兴趣的区间（绘图和拟合都只在这个范围内）\n",
    "focus_range = (0.7, 0.8)\n",
    "# 自定义Y轴范围\n",
    "ylim_range = (0.7, 0.9)\n",
    "\n",
    "# 拟合与统计参数\n",
    "poly_degree = 5  # 多项式拟合阶数\n",
    "confidence_level = 1.96  # 仍需计算置信区间，这里保持95%\n",
    "\n",
    "# 图表样式\n",
    "figsize = (10, 6)\n",
    "title_font = {'family': 'Arial', 'size': 22, 'weight': 'bold'}\n",
    "label_font = {'family': 'Arial', 'size': 20, 'weight': 'bold'}\n",
    "tick_font = {'family': 'Arial', 'size': 18}\n",
    "\n",
    "# 线条和颜色样式\n",
    "raw_curve_style = {'color': 'gray', 'linestyle': '--', 'linewidth': 2, 'label': '原始平均曲线'}\n",
    "fit_curve_style = {'color': 'red', 'linestyle': '-', 'linewidth': 3, 'label': f'{poly_degree}阶多项式拟合'}\n",
    "\n",
    "# ==================== 函数定义 ====================\n",
    "def load_data_and_model():\n",
    "    \"\"\"加载数据和模型\"\"\"\n",
    "    df = pd.read_excel(input_path)\n",
    "    missing_cols = [col for col in [target_column, feature_to_plot] if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"缺失列: {', '.join(missing_cols)}\")\n",
    "    \n",
    "    X = df.drop(columns=[target_column]).select_dtypes(include=['number'])\n",
    "    model = joblib.load(model_path)\n",
    "    return X, model\n",
    "\n",
    "def polynomial_func(x, *coefficients):\n",
    "    \"\"\"多项式函数，用于曲线拟合\"\"\"\n",
    "    return sum(c * x**i for i, c in enumerate(coefficients))\n",
    "\n",
    "def calculate_and_fit_data():\n",
    "    \"\"\"计算指定区间内的ICE数据（含置信区间）并进行拟合\"\"\"\n",
    "    X, model = load_data_and_model()\n",
    "    \n",
    "    grid_values = np.linspace(focus_range[0] - 0.01, focus_range[1] + 0.01, 500)\n",
    "    all_predictions = []\n",
    "\n",
    "    print(f\"正在计算每个样本的ICE曲线...\")\n",
    "    for idx, (_, sample) in enumerate(X.iterrows()):\n",
    "        X_ice = pd.DataFrame([sample.values] * len(grid_values), columns=X.columns)\n",
    "        X_ice[feature_to_plot] = grid_values\n",
    "        preds = model.predict(xgb.DMatrix(X_ice))\n",
    "        all_predictions.append(preds)\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"已处理 {idx + 1} 个样本...\")\n",
    "\n",
    "    predictions_array = np.array(all_predictions)\n",
    "    mean_preds = predictions_array.mean(axis=0)\n",
    "    std_preds = predictions_array.std(axis=0)  # 仍需计算标准差\n",
    "    \n",
    "    # 计算置信区间上下界（用于导出）\n",
    "    lower_bound = mean_preds - confidence_level * std_preds\n",
    "    upper_bound = mean_preds + confidence_level * std_preds\n",
    "    \n",
    "    full_df = pd.DataFrame({\n",
    "        feature_to_plot: grid_values,\n",
    "        'Mean_Pred': mean_preds,\n",
    "        'Std_Pred': std_preds,\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound\n",
    "    })\n",
    "    \n",
    "    mask = (full_df[feature_to_plot] >= focus_range[0]) & (full_df[feature_to_plot] <= focus_range[1])\n",
    "    focused_df = full_df[mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    print(f\"在区间 {focus_range} 内找到 {len(focused_df)} 个数据点，准备进行拟合...\")\n",
    "\n",
    "    if focused_df.empty:\n",
    "        raise ValueError(f\"在指定的区间 {focus_range} 内没有找到任何数据点。\")\n",
    "\n",
    "    x_for_fit = focused_df[feature_to_plot].values\n",
    "    y_for_fit = focused_df['Mean_Pred'].values\n",
    "    \n",
    "    initial_guess = [1] * (poly_degree + 1)\n",
    "    params, _ = curve_fit(\n",
    "        polynomial_func, \n",
    "        x_for_fit, \n",
    "        y_for_fit,\n",
    "        p0=initial_guess,\n",
    "        maxfev=10000\n",
    "    )\n",
    "    \n",
    "    x_fit_smooth = np.linspace(focus_range[0], focus_range[1], 300)\n",
    "    y_fit_smooth = polynomial_func(x_fit_smooth, *params)\n",
    "    \n",
    "    return focused_df, x_fit_smooth, y_fit_smooth\n",
    "\n",
    "def plot_and_export_results(focused_df, x_fit_smooth, y_fit_smooth):\n",
    "    \"\"\"绘制并导出指定区间内的结果（图中不显示置信区间）\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 导出数据到Excel（包含置信区间数据）\n",
    "    output_filename = f\"ice_focused_on_{focus_range[0]}_{focus_range[1]}_{feature_to_plot.replace('.', '_')}_with_ci_data.xlsx\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    export_df = focused_df[[feature_to_plot, 'Mean_Pred', 'Std_Pred', 'Lower_Bound', 'Upper_Bound']].copy()\n",
    "    export_df.columns = [feature_to_plot, '原始平均预测值', '预测值标准差', '95%置信区间下界', '95%置信区间上界']\n",
    "    \n",
    "    fit_curve_df = pd.DataFrame({\n",
    "        feature_to_plot: x_fit_smooth,\n",
    "        '拟合曲线预测值': y_fit_smooth\n",
    "    })\n",
    "    \n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        export_df.to_excel(writer, sheet_name='区间内原始数据(含置信区间)', index=False)\n",
    "        fit_curve_df.to_excel(writer, sheet_name='拟合曲线数据', index=False)\n",
    "        \n",
    "    print(f\"数据已导出至: {output_path}\")\n",
    "    \n",
    "    # 绘制图表（不包含置信区间）\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # 绘制原始平均曲线（灰色虚线）\n",
    "    ax.plot(focused_df[feature_to_plot], focused_df['Mean_Pred'], **raw_curve_style)\n",
    "    \n",
    "    # 绘制拟合曲线（红色实线）\n",
    "    ax.plot(x_fit_smooth, y_fit_smooth, **fit_curve_style)\n",
    "    \n",
    "    # 精确设置坐标轴范围\n",
    "    ax.set_xlim(focus_range)\n",
    "    ax.set_ylim(ylim_range)\n",
    "    \n",
    "    # 设置图表标题和标签\n",
    "    ax.set_title(f'ICE分析: {feature_to_plot} (聚焦区间: {focus_range[0]} - {focus_range[1]})', fontdict=title_font)\n",
    "    ax.set_xlabel(feature_to_plot, fontdict=label_font)\n",
    "    ax.set_ylabel('预测值', fontdict=label_font)\n",
    "    \n",
    "    # 设置刻度字体\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_font['size'])\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontproperties(tick_font)\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(tick_font)\n",
    "    \n",
    "    # 设置图例\n",
    "    ax.legend(prop=tick_font, frameon=False, fancybox=False, shadow=False)\n",
    "    \n",
    "    # 添加网格线\n",
    "    ax.grid(False, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # 保存图表\n",
    "    plot_filename = f\"ice_focused_on_{focus_range[0]}_{focus_range[1]}_{feature_to_plot.replace('.', '_')}_no_ci_plot.png\"\n",
    "    plot_path = os.path.join(output_dir, plot_filename)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"图表已保存至: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"开始生成 '{feature_to_plot}' 在区间 {focus_range} 内的ICE分析图 (图中不显示置信区间)...\")\n",
    "    try:\n",
    "        focused_df, x_fit_smooth, y_fit_smooth = calculate_and_fit_data()\n",
    "        plot_and_export_results(focused_df, x_fit_smooth, y_fit_smooth)\n",
    "    except Exception as e:\n",
    "        print(f\"错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac65c768-2aa0-4c5b-812e-5e018a90062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始生成 'EN.' 在区间 (0.7, 0.8) 内的ICE分析图...\n",
      "正在计算每个样本的ICE曲线...\n",
      "已处理 50 个样本...\n",
      "已处理 100 个样本...\n",
      "已处理 150 个样本...\n",
      "已处理 200 个样本...\n",
      "在区间 (0.7, 0.8) 内找到 416 个数据点，准备进行拟合...\n",
      "数据已导出至: ice_smooth_results\\ice_focused_on_0.7_0.8_EN_.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 26512 (\\N{CJK UNIFIED IDEOGRAPH-6790}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 32858 (\\N{CJK UNIFIED IDEOGRAPH-805A}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 28966 (\\N{CJK UNIFIED IDEOGRAPH-7126}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 21306 (\\N{CJK UNIFIED IDEOGRAPH-533A}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 38388 (\\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 20449 (\\N{CJK UNIFIED IDEOGRAPH-4FE1}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 21407 (\\N{CJK UNIFIED IDEOGRAPH-539F}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 22987 (\\N{CJK UNIFIED IDEOGRAPH-59CB}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 24179 (\\N{CJK UNIFIED IDEOGRAPH-5E73}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 38454 (\\N{CJK UNIFIED IDEOGRAPH-9636}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 22810 (\\N{CJK UNIFIED IDEOGRAPH-591A}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 39033 (\\N{CJK UNIFIED IDEOGRAPH-9879}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 24335 (\\N{CJK UNIFIED IDEOGRAPH-5F0F}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 25311 (\\N{CJK UNIFIED IDEOGRAPH-62DF}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:177: UserWarning: Glyph 21512 (\\N{CJK UNIFIED IDEOGRAPH-5408}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 20540 (\\N{CJK UNIFIED IDEOGRAPH-503C}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 26512 (\\N{CJK UNIFIED IDEOGRAPH-6790}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 32858 (\\N{CJK UNIFIED IDEOGRAPH-805A}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 28966 (\\N{CJK UNIFIED IDEOGRAPH-7126}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 21306 (\\N{CJK UNIFIED IDEOGRAPH-533A}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 38388 (\\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 32622 (\\N{CJK UNIFIED IDEOGRAPH-7F6E}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 20449 (\\N{CJK UNIFIED IDEOGRAPH-4FE1}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 21407 (\\N{CJK UNIFIED IDEOGRAPH-539F}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 22987 (\\N{CJK UNIFIED IDEOGRAPH-59CB}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 24179 (\\N{CJK UNIFIED IDEOGRAPH-5E73}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 38454 (\\N{CJK UNIFIED IDEOGRAPH-9636}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 22810 (\\N{CJK UNIFIED IDEOGRAPH-591A}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 39033 (\\N{CJK UNIFIED IDEOGRAPH-9879}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 24335 (\\N{CJK UNIFIED IDEOGRAPH-5F0F}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 25311 (\\N{CJK UNIFIED IDEOGRAPH-62DF}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "C:\\Users\\miaoxinyi\\AppData\\Local\\Temp\\ipykernel_30288\\3244283329.py:178: UserWarning: Glyph 21512 (\\N{CJK UNIFIED IDEOGRAPH-5408}) missing from font(s) Arial.\n",
      "  plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图表已保存至: ice_smooth_results\\ice_focused_on_0.7_0.8_EN_.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# ==================== 参数配置 ====================\n",
    "model_path = \"xgboost_model_ncv/xgboost_model.pkl\"\n",
    "input_path = \"归一化数据-20251120.xlsx\"\n",
    "output_dir = \"ice_smooth_results\"\n",
    "target_column = \"SO2 tolerance\"\n",
    "feature_to_plot = \"EN.\"\n",
    "\n",
    "# 感兴趣的区间（绘图和拟合都只在这个范围内）\n",
    "focus_range = (0.7, 0.8)\n",
    "\n",
    "# 拟合参数\n",
    "poly_degree = 5  # 多项式拟合阶数\n",
    "confidence_level = 1.96  # 95%置信区间的系数\n",
    "\n",
    "# 图表样式\n",
    "figsize = (10, 6)\n",
    "title_font = {'family': 'Arial', 'size': 16, 'weight': 'bold'}\n",
    "label_font = {'family': 'Arial', 'size': 14, 'weight': 'bold'}\n",
    "tick_font = {'family': 'Arial', 'size': 12}\n",
    "\n",
    "# 线条和颜色样式\n",
    "raw_curve_style = {'color': 'gray', 'linestyle': '--', 'linewidth': 2, 'label': '原始平均曲线'}\n",
    "fit_curve_style = {'color': 'red', 'linestyle': '-', 'linewidth': 3, 'label': f'{poly_degree}阶多项式拟合'}\n",
    "confidence_interval_style = {'color': 'gray', 'alpha': 0.3, 'label': '95% 置信区间'}\n",
    "\n",
    "# ==================== 函数定义 ====================\n",
    "def load_data_and_model():\n",
    "    \"\"\"加载数据和模型\"\"\"\n",
    "    df = pd.read_excel(input_path)\n",
    "    missing_cols = [col for col in [target_column, feature_to_plot] if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"缺失列: {', '.join(missing_cols)}\")\n",
    "    \n",
    "    X = df.drop(columns=[target_column]).select_dtypes(include=['number'])\n",
    "    model = joblib.load(model_path)\n",
    "    return X, model\n",
    "\n",
    "def polynomial_func(x, *coefficients):\n",
    "    \"\"\"多项式函数，用于曲线拟合\"\"\"\n",
    "    return sum(c * x**i for i, c in enumerate(coefficients))\n",
    "\n",
    "def calculate_and_fit_data():\n",
    "    \"\"\"计算指定区间内的ICE数据并进行拟合\"\"\"\n",
    "    X, model = load_data_and_model()\n",
    "    \n",
    "    # 为了获得更精细的结果，在稍宽的范围内生成网格点，之后再精确筛选\n",
    "    grid_values = np.linspace(focus_range[0] - 0.01, focus_range[1] + 0.01, 500)\n",
    "    all_predictions = []\n",
    "\n",
    "    print(f\"正在计算每个样本的ICE曲线...\")\n",
    "    for idx, (_, sample) in enumerate(X.iterrows()):\n",
    "        X_ice = pd.DataFrame([sample.values] * len(grid_values), columns=X.columns)\n",
    "        X_ice[feature_to_plot] = grid_values\n",
    "        preds = model.predict(xgb.DMatrix(X_ice))\n",
    "        all_predictions.append(preds)\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"已处理 {idx + 1} 个样本...\")\n",
    "\n",
    "    # 计算平均曲线和标准差\n",
    "    predictions_array = np.array(all_predictions)\n",
    "    mean_preds = predictions_array.mean(axis=0)\n",
    "    std_preds = predictions_array.std(axis=0)\n",
    "    \n",
    "    # 创建DataFrame并精确筛选出我们关注的区间\n",
    "    full_df = pd.DataFrame({\n",
    "        feature_to_plot: grid_values,\n",
    "        'Mean_Pred': mean_preds,\n",
    "        'Std_Pred': std_preds\n",
    "    })\n",
    "    mask = (full_df[feature_to_plot] >= focus_range[0]) & (full_df[feature_to_plot] <= focus_range[1])\n",
    "    focused_df = full_df[mask].copy().reset_index(drop=True)\n",
    "    \n",
    "    print(f\"在区间 {focus_range} 内找到 {len(focused_df)} 个数据点，准备进行拟合...\")\n",
    "\n",
    "    if focused_df.empty:\n",
    "        raise ValueError(f\"在指定的区间 {focus_range} 内没有找到任何数据点。\")\n",
    "\n",
    "    # 使用筛选后的数据进行多项式拟合\n",
    "    x_for_fit = focused_df[feature_to_plot].values\n",
    "    y_for_fit = focused_df['Mean_Pred'].values\n",
    "    \n",
    "    initial_guess = [1] * (poly_degree + 1)\n",
    "    params, _ = curve_fit(\n",
    "        polynomial_func, \n",
    "        x_for_fit, \n",
    "        y_for_fit,\n",
    "        p0=initial_guess,\n",
    "        maxfev=10000\n",
    "    )\n",
    "    \n",
    "    # 为了使拟合曲线看起来更平滑，在关注区间内生成更密集的点来绘制拟合线\n",
    "    x_fit_smooth = np.linspace(focus_range[0], focus_range[1], 300)\n",
    "    y_fit_smooth = polynomial_func(x_fit_smooth, *params)\n",
    "    \n",
    "    return focused_df, x_fit_smooth, y_fit_smooth\n",
    "\n",
    "def plot_and_export_results(focused_df, x_fit_smooth, y_fit_smooth):\n",
    "    \"\"\"绘制并导出指定区间内的结果\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 导出数据到Excel\n",
    "    output_filename = f\"ice_focused_on_{focus_range[0]}_{focus_range[1]}_{feature_to_plot.replace('.', '_')}.xlsx\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # 准备导出数据，包括原始平均点和拟合后的平滑点\n",
    "    export_df = focused_df[[feature_to_plot, 'Mean_Pred', 'Std_Pred']].copy()\n",
    "    export_df.columns = [feature_to_plot, '原始平均预测值', '预测值标准差']\n",
    "    \n",
    "    # 添加拟合曲线的数据\n",
    "    fit_curve_df = pd.DataFrame({\n",
    "        feature_to_plot: x_fit_smooth,\n",
    "        '原始平均预测值': np.nan,\n",
    "        '预测值标准差': np.nan\n",
    "    })\n",
    "    fit_curve_df['拟合曲线预测值'] = y_fit_smooth\n",
    "    \n",
    "    # 使用ExcelWriter将数据写入不同的工作表\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        export_df.to_excel(writer, sheet_name='区间内原始数据', index=False)\n",
    "        fit_curve_df.to_excel(writer, sheet_name='拟合曲线数据', index=False)\n",
    "        \n",
    "    print(f\"数据已导出至: {output_path}\")\n",
    "    \n",
    "    # 绘制图表\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # 绘制置信区间\n",
    "    ax.fill_between(\n",
    "        focused_df[feature_to_plot],\n",
    "        focused_df['Mean_Pred'] - confidence_level * focused_df['Std_Pred'],\n",
    "        focused_df['Mean_Pred'] + confidence_level * focused_df['Std_Pred'],\n",
    "        **confidence_interval_style\n",
    "    )\n",
    "    \n",
    "    # 绘制原始平均曲线（灰色虚线）\n",
    "    ax.plot(focused_df[feature_to_plot], focused_df['Mean_Pred'], **raw_curve_style)\n",
    "    \n",
    "    # 绘制拟合曲线（红色实线）\n",
    "    ax.plot(x_fit_smooth, y_fit_smooth, **fit_curve_style)\n",
    "    \n",
    "    # 精确设置坐标轴范围，只显示我们关注的区间\n",
    "    ax.set_xlim(focus_range)\n",
    "    # y轴范围可以自动调整，也可以手动设置以突出变化\n",
    "    # ax.set_ylim([y_min, y_max]) \n",
    "    \n",
    "    # 设置图表标题和标签\n",
    "    ax.set_title(f'ICE分析: {feature_to_plot} (聚焦区间: {focus_range[0]} - {focus_range[1]})', fontdict=title_font)\n",
    "    ax.set_xlabel(feature_to_plot, fontdict=label_font)\n",
    "    ax.set_ylabel('预测值', fontdict=label_font)\n",
    "    \n",
    "    # 设置刻度字体\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_font['size'])\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontproperties(tick_font)\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(tick_font)\n",
    "    \n",
    "    # 设置图例\n",
    "    ax.legend(prop=tick_font, frameon=True, fancybox=True, shadow=True)\n",
    "    \n",
    "    # 添加网格线\n",
    "    ax.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # 保存图表\n",
    "    plot_filename = f\"ice_focused_on_{focus_range[0]}_{focus_range[1]}_{feature_to_plot.replace('.', '_')}.png\"\n",
    "    plot_path = os.path.join(output_dir, plot_filename)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"图表已保存至: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"开始生成 '{feature_to_plot}' 在区间 {focus_range} 内的ICE分析图...\")\n",
    "    try:\n",
    "        focused_df, x_fit_smooth, y_fit_smooth = calculate_and_fit_data()\n",
    "        plot_and_export_results(focused_df, x_fit_smooth, y_fit_smooth)\n",
    "    except Exception as e:\n",
    "        print(f\"错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848187fe-182e-4b05-858b-809bc02144b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始EN.和I.R.的2D部分依赖分析...\n",
      "加载数据和模型...\n",
      "计算2D部分依赖...\n",
      "绘制2D PDP热力图...\n",
      "2D PDP热力图已保存至：pdp_analysis\\pdp_2d_EN._I.R..png\n",
      "绘制2D PDP等高线图...\n",
      "2D PDP等高线图已保存至：pdp_analysis\\contour_pdp_2d_EN._I.R..png\n",
      "保存PDP分析数据...\n",
      "PDP数据已保存至：pdp_analysis\\pdp_2d_EN._I.R..csv\n",
      "\n",
      "EN.和I.R.的2D部分依赖分析完成！所有结果保存在目录：pdp_analysis\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# 参数配置\n",
    "model_path = \"xgboost_model_ncv/xgboost_model.pkl\"  # 模型路径\n",
    "input_path = \"归一化数据-20251120.xlsx\"  # 输入数据路径\n",
    "output_dir = \"pdp_analysis\"  # 输出目录\n",
    "feature1 = \"EN.\"  # 第一个特征\n",
    "feature2 = \"I.R.\"  # 第二个特征\n",
    "random_state = 42  # 随机种子\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def prepare_data(input_path):\n",
    "    \"\"\"数据加载与预处理\"\"\"\n",
    "    df = pd.read_excel(input_path)\n",
    "    return df\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"加载训练好的XGBoost模型\"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "def calculate_pdp_2d(model, df, feature1, feature2, num_points=20):\n",
    "    \"\"\"计算两个特征的2D部分依赖\"\"\"\n",
    "    # 确保特征存在\n",
    "    if feature1 not in df.columns or feature2 not in df.columns:\n",
    "        raise ValueError(f\"特征 {feature1} 或 {feature2} 不存在于数据中\")\n",
    "    \n",
    "    # 保存原始特征值\n",
    "    original_features = df[[feature1, feature2]].copy()\n",
    "    \n",
    "    # 生成特征网格\n",
    "    feature1_values = np.linspace(df[feature1].min(), df[feature1].max(), num_points)\n",
    "    feature2_values = np.linspace(df[feature2].min(), df[feature2].max(), num_points)\n",
    "    feature1_mesh, feature2_mesh = np.meshgrid(feature1_values, feature2_values)\n",
    "    \n",
    "    # 初始化预测结果数组\n",
    "    pdp_values = np.zeros((num_points, num_points))\n",
    "    \n",
    "    # 对每个特征组合计算预测值\n",
    "    for i, f1_val in enumerate(feature1_values):\n",
    "        for j, f2_val in enumerate(feature2_values):\n",
    "            # 创建临时数据副本\n",
    "            temp_df = df.copy()\n",
    "            temp_df[feature1] = f1_val\n",
    "            temp_df[feature2] = f2_val\n",
    "            \n",
    "            # 准备特征矩阵\n",
    "            X = temp_df.drop(columns=[col for col in temp_df.columns \n",
    "                                     if col not in model.feature_names])\n",
    "            \n",
    "            # 进行预测\n",
    "            dmatrix = xgb.DMatrix(X)\n",
    "            predictions = model.predict(dmatrix)\n",
    "            \n",
    "            # 计算平均预测值作为PDP值\n",
    "            pdp_values[j, i] = np.mean(predictions)\n",
    "    \n",
    "    # 新增：返回原始的一维特征值数组\n",
    "    return feature1_mesh, feature2_mesh, pdp_values, feature1_values, feature2_values\n",
    "\n",
    "def plot_pdp_2d(feature1, feature2, feature1_mesh, feature2_mesh, pdp_values, output_dir):\n",
    "    \"\"\"绘制2D部分依赖图\"\"\"\n",
    "    # 设置全局字体样式\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    \n",
    "    # 创建自定义颜色映射\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\n",
    "        'blue_to_red', ['#1f77b4', '#ffffff', '#d62728'], N=256)\n",
    "    \n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(14, 12), facecolor='white')\n",
    "    \n",
    "    # 绘制热力图\n",
    "    im = ax.pcolormesh(\n",
    "        feature1_mesh, feature2_mesh, pdp_values,\n",
    "        cmap=custom_cmap, shading='auto',\n",
    "        vmin=pdp_values.min(), vmax=pdp_values.max()\n",
    "    )\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = fig.colorbar(im, ax=ax, pad=0.02)\n",
    "    cbar.set_label('Predicted Value', fontsize=24, fontname='Arial', fontweight='bold')\n",
    "    cbar.ax.tick_params(labelsize=20, direction='out', length=6, width=2)\n",
    "    \n",
    "    # 设置坐标轴标签和标题\n",
    "    ax.set_xlabel(feature1, fontsize=28, fontname='Arial', fontweight='bold', labelpad=10)\n",
    "    ax.set_ylabel(feature2, fontsize=28, fontname='Arial', fontweight='bold', labelpad=10)\n",
    "    ax.set_title(f'2D Partial Dependence Plot for {feature1} and {feature2}',\n",
    "                fontsize=32, fontname='Arial', fontweight='bold', pad=20)\n",
    "    \n",
    "    # 设置坐标轴刻度\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(nbins=6, integer=False))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=6, integer=False))\n",
    "    \n",
    "    # 设置刻度标签样式\n",
    "    for tick in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        tick.set_fontname('Arial')\n",
    "        tick.set_fontsize(20)\n",
    "        tick.set_weight('bold')\n",
    "    \n",
    "    # 设置边框样式\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2.5)\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    # 添加网格线\n",
    "    ax.grid(True, linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图形\n",
    "    plot_path = os.path.join(output_dir, f\"pdp_2d_{feature1}_{feature2}.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return plot_path\n",
    "\n",
    "def plot_contour_pdp_2d(feature1, feature2, feature1_mesh, feature2_mesh, pdp_values, output_dir):\n",
    "    \"\"\"绘制2D部分依赖的等高线图（优化标签堆叠）\"\"\"\n",
    "    # 设置全局字体样式\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    \n",
    "    # 创建自定义颜色映射\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\n",
    "        'blue_to_red', ['#1f77b4', '#ffffff', '#d62728'], N=256)\n",
    "    \n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(14, 12), facecolor='white')\n",
    "    \n",
    "    # 绘制等高线图\n",
    "    contour = ax.contourf(\n",
    "        feature1_mesh, feature2_mesh, pdp_values,\n",
    "        cmap=custom_cmap, levels=15,\n",
    "        vmin=pdp_values.min(), vmax=pdp_values.max()\n",
    "    )\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = fig.colorbar(contour, ax=ax, pad=0.02)\n",
    "    cbar.set_label('Predicted Value', fontsize=24, fontname='Arial', fontweight='bold')\n",
    "    cbar.ax.tick_params(labelsize=20, direction='out', length=6, width=2)\n",
    "    \n",
    "    # 添加等高线（仅绘制关键等高线，减少密集标注）\n",
    "    contour_lines = ax.contour(\n",
    "        feature1_mesh, feature2_mesh, pdp_values,\n",
    "        colors='black', linewidths=1.5, levels=8  # 减少 levels 数量，控制标注密度\n",
    "    )\n",
    "    \n",
    "    # 优化：仅在稀疏区域标注，避免堆叠\n",
    "    ax.clabel(contour_lines, inline=True, fontsize=16, levels=contour_lines.levels[::2])\n",
    "    \n",
    "    # 设置坐标轴标签和标题\n",
    "    ax.set_xlabel(feature1, fontsize=28, fontname='Arial', fontweight='bold', labelpad=10)\n",
    "    ax.set_ylabel(feature2, fontsize=28, fontname='Arial', fontweight='bold', labelpad=10)\n",
    "    # 修改：标题中去掉了“(Marked Key Points)”\n",
    "    ax.set_title(f'Contour Plot of 2D Partial Dependence for {feature1} and {feature2}',\n",
    "                fontsize=32, fontname='Arial', fontweight='bold', pad=20)\n",
    "    \n",
    "    # 设置坐标轴刻度\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(nbins=6, integer=False))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=6, integer=False))\n",
    "    \n",
    "    # 设置刻度标签样式\n",
    "    for tick in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        tick.set_fontname('Arial')\n",
    "        tick.set_fontsize(20)\n",
    "        tick.set_weight('bold')\n",
    "    \n",
    "    # 设置边框样式\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2.5)\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    # 添加网格线\n",
    "    ax.grid(True, linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图形\n",
    "    plot_path = os.path.join(output_dir, f\"contour_pdp_2d_{feature1}_{feature2}.png\")\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return plot_path\n",
    "\n",
    "def main():\n",
    "    print(f\"开始{feature1}和{feature2}的2D部分依赖分析...\")\n",
    "    \n",
    "    # 1. 加载数据和模型\n",
    "    print(\"加载数据和模型...\")\n",
    "    df = prepare_data(input_path)\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # 2. 计算2D部分依赖\n",
    "    print(\"计算2D部分依赖...\")\n",
    "    # 修改：接收 feature1_values 和 feature2_values\n",
    "    feature1_mesh, feature2_mesh, pdp_values, feature1_values, feature2_values = calculate_pdp_2d(\n",
    "        model, df, feature1, feature2, num_points=25)\n",
    "    \n",
    "    # 3. 绘制2D PDP热力图\n",
    "    print(\"绘制2D PDP热力图...\")\n",
    "    heatmap_path = plot_pdp_2d(\n",
    "        feature1, feature2, feature1_mesh, feature2_mesh, pdp_values, output_dir)\n",
    "    print(f\"2D PDP热力图已保存至：{heatmap_path}\")\n",
    "    \n",
    "    # 4. 绘制2D PDP等高线图\n",
    "    print(\"绘制2D PDP等高线图...\")\n",
    "    # 修改：调用时不再需要传递 feature1_values 和 feature2_values\n",
    "    contour_path = plot_contour_pdp_2d(\n",
    "        feature1, feature2, feature1_mesh, feature2_mesh, pdp_values, output_dir)\n",
    "    print(f\"2D PDP等高线图已保存至：{contour_path}\")\n",
    "    \n",
    "    # 5. 保存PDP数据\n",
    "    print(\"保存PDP分析数据...\")\n",
    "    pdp_data = {\n",
    "        'feature1_values': feature1_mesh.flatten(),\n",
    "        'feature2_values': feature2_mesh.flatten(),\n",
    "        'pdp_values': pdp_values.flatten()\n",
    "    }\n",
    "    pdp_df = pd.DataFrame(pdp_data)\n",
    "    pdp_df.to_csv(os.path.join(output_dir, f\"pdp_2d_{feature1}_{feature2}.csv\"), index=False)\n",
    "    print(f\"PDP数据已保存至：{os.path.join(output_dir, f'pdp_2d_{feature1}_{feature2}.csv')}\")\n",
    "    \n",
    "    print(f\"\\n{feature1}和{feature2}的2D部分依赖分析完成！所有结果保存在目录：{output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1471c75-a4a7-47e4-ac50-6d2e50abb376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "特征消融分析 (Feature Ablation Analysis)\n",
      "============================================================\n",
      "\n",
      "步骤 1/3: 加载完整数据并划分训练/测试集...\n",
      "训练集大小: (193, 19), 测试集大小: (49, 19)\n",
      "\n",
      "步骤 2/3: 训练基准模型 (使用所有特征)...\n",
      "\n",
      "基准模型性能 (使用所有特征):\n",
      "  - 训练集 R²: 0.9989\n",
      "  - 测试集 R²: 0.7779\n",
      "\n",
      "步骤 3/3: 开始依次移除特征并重新训练...\n",
      "\n",
      "--- 正在移除特征: 'EN.' ---\n",
      "  - 剩余特征数: 18\n",
      "  - 训练集 R²: 0.9989\n",
      "  - 测试集 R²: 0.7665\n",
      "  - 与基准相比 R² 变化: -0.0114\n",
      "\n",
      "--- 正在移除特征: 'I.R.' ---\n",
      "  - 剩余特征数: 18\n",
      "  - 训练集 R²: 0.9989\n",
      "  - 测试集 R²: 0.7766\n",
      "  - 与基准相比 R² 变化: -0.0013\n",
      "\n",
      "--- 正在移除特征: 'I.E.' ---\n",
      "  - 剩余特征数: 18\n",
      "  - 训练集 R²: 0.9992\n",
      "  - 测试集 R²: 0.7690\n",
      "  - 与基准相比 R² 变化: -0.0089\n",
      "\n",
      "--- 正在移除特征: 'Density' ---\n",
      "  - 剩余特征数: 18\n",
      "  - 训练集 R²: 0.9989\n",
      "  - 测试集 R²: 0.7907\n",
      "  - 与基准相比 R² 变化: 0.0128\n",
      "\n",
      "--- 正在移除特征: 'M.P.' ---\n",
      "  - 剩余特征数: 18\n",
      "  - 训练集 R²: 0.9987\n",
      "  - 测试集 R²: 0.7848\n",
      "  - 与基准相比 R² 变化: 0.0069\n",
      "\n",
      "--- 正在移除特征: 'T.C.' ---\n",
      "  - 剩余特征数: 18\n",
      "  - 训练集 R²: 0.9979\n",
      "  - 测试集 R²: 0.7919\n",
      "  - 与基准相比 R² 变化: 0.0140\n",
      "\n",
      "============================================================\n",
      "消融分析结果汇总\n",
      "============================================================\n",
      "  Removed_Feature  Remaining_Features  Train_R2  Test_R2  R2_Change_From_Base\n",
      "None (Base Model)                  19  0.998865 0.777910             0.000000\n",
      "              EN.                  18  0.998884 0.766541            -0.011369\n",
      "             I.R.                  18  0.998886 0.776626            -0.001283\n",
      "             I.E.                  18  0.999153 0.768960            -0.008949\n",
      "          Density                  18  0.998896 0.790664             0.012754\n",
      "             M.P.                  18  0.998708 0.784785             0.006875\n",
      "             T.C.                  18  0.997911 0.791939             0.014029\n",
      "\n",
      "详细结果已保存至: xgboost_ablation_analysis\\ablation_analysis_results.csv\n",
      "\n",
      "--- 关键发现 ---\n",
      "1. 移除后性能下降最显著的特征: 'EN.'\n",
      "   - R² 变化: -0.0114\n",
      "   - 该特征对模型性能至关重要。\n",
      "\n",
      "2. 移除后性能下降最少（或提升）的特征: 'T.C.'\n",
      "   - R² 变化: 0.0140\n",
      "   - 该特征可能是冗余的，或其信息可被其他特征替代。\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# ==================== 参数配置 ====================\n",
    "# 请确保这些参数与你原始训练脚本中的参数一致\n",
    "input_path = \"归一化数据-20251120.xlsx\"\n",
    "target_column = \"SO2 tolerance\"\n",
    "outer_test_size = 0.2\n",
    "random_state = 42\n",
    "model_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': random_state,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# 指定要依次移除的特征列表\n",
    "features_to_ablate = ['EN.', 'I.R.', 'I.E.', 'Density', 'M.P.', 'T.C.']\n",
    "\n",
    "# 输出目录\n",
    "output_dir = \"xgboost_ablation_analysis\"\n",
    "\n",
    "# ==================== 函数定义 (复用自原脚本) ====================\n",
    "def prepare_data(input_path, target_column, features_to_drop=None):\n",
    "    \"\"\"数据加载与预处理\"\"\"\n",
    "    df = pd.read_excel(input_path)\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"目标列 {target_column} 不存在于数据中\")\n",
    "    \n",
    "    y = df[target_column]\n",
    "    X = df.drop(columns=[target_column])\n",
    "\n",
    "    # 如果指定了要删除的特征，则在数据预处理阶段就移除它们\n",
    "    if features_to_drop:\n",
    "        # 确保要删除的特征确实存在\n",
    "        features_to_drop = [f for f in features_to_drop if f in X.columns]\n",
    "        if features_to_drop:\n",
    "            X = X.drop(columns=features_to_drop)\n",
    "            print(f\"已从数据中移除特征: {', '.join(features_to_drop)}\")\n",
    "    \n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "    return X[numeric_cols], y\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, params):\n",
    "    \"\"\"训练模型并返回评估结果\"\"\"\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    ddata_train = xgb.DMatrix(X_train)\n",
    "    ddata_test = xgb.DMatrix(X_test)\n",
    "    \n",
    "    y_pred_train = model.predict(ddata_train)\n",
    "    y_pred_test = model.predict(ddata_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'Train R2': r2_score(y_train, y_pred_train),\n",
    "        'Test R2': r2_score(y_test, y_pred_test)\n",
    "    }\n",
    "    return model, metrics\n",
    "\n",
    "# ==================== 主程序：消融分析 ====================\n",
    "def main():\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"特征消融分析 (Feature Ablation Analysis)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. 加载完整数据并划分训练集和测试集\n",
    "    # 这一步非常关键：我们在完整数据集上划分一次，\n",
    "    # 后续所有的消融实验都将使用这个固定的划分，以保证结果的可比性。\n",
    "    print(\"\\n步骤 1/3: 加载完整数据并划分训练/测试集...\")\n",
    "    X_full, y_full = prepare_data(input_path, target_column)\n",
    "    X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "        X_full, y_full, test_size=outer_test_size, random_state=random_state\n",
    "    )\n",
    "    print(f\"训练集大小: {X_train_full.shape}, 测试集大小: {X_test_full.shape}\")\n",
    "\n",
    "    # 2. 训练基准模型 (使用所有特征)\n",
    "    print(\"\\n步骤 2/3: 训练基准模型 (使用所有特征)...\")\n",
    "    base_model, base_metrics = train_and_evaluate(\n",
    "        X_train_full, y_train_full, X_test_full, y_test_full, model_params\n",
    "    )\n",
    "    joblib.dump(base_model, os.path.join(output_dir, \"base_model_with_all_features.pkl\"))\n",
    "    \n",
    "    print(\"\\n基准模型性能 (使用所有特征):\")\n",
    "    print(f\"  - 训练集 R²: {base_metrics['Train R2']:.4f}\")\n",
    "    print(f\"  - 测试集 R²: {base_metrics['Test R2']:.4f}\")\n",
    "\n",
    "    # 3. 开始消融实验\n",
    "    print(\"\\n步骤 3/3: 开始依次移除特征并重新训练...\")\n",
    "    results = []\n",
    "    \n",
    "    # 记录基准结果\n",
    "    results.append({\n",
    "        'Removed_Feature': 'None (Base Model)',\n",
    "        'Remaining_Features': X_full.shape[1],\n",
    "        'Train_R2': base_metrics['Train R2'],\n",
    "        'Test_R2': base_metrics['Test R2'],\n",
    "        'R2_Change_From_Base': 0.0\n",
    "    })\n",
    "\n",
    "    for feature in features_to_ablate:\n",
    "        print(f\"\\n--- 正在移除特征: '{feature}' ---\")\n",
    "        \n",
    "        # 从训练集和测试集中同时移除该特征\n",
    "        if feature in X_train_full.columns:\n",
    "            X_train_ablated = X_train_full.drop(columns=[feature])\n",
    "            X_test_ablated = X_test_full.drop(columns=[feature])\n",
    "        else:\n",
    "            print(f\"警告: 特征 '{feature}' 不在数据集中，跳过此次实验。\")\n",
    "            continue\n",
    "\n",
    "        # 训练消融后的模型\n",
    "        ablated_model, ablated_metrics = train_and_evaluate(\n",
    "            X_train_ablated, y_train_full, X_test_ablated, y_test_full, model_params\n",
    "        )\n",
    "        \n",
    "        # 保存模型\n",
    "        joblib.dump(ablated_model, os.path.join(output_dir, f\"model_without_{feature.replace('.', '_')}.pkl\"))\n",
    "        \n",
    "        # 计算与基准模型的 R² 变化\n",
    "        r2_change = ablated_metrics['Test R2'] - base_metrics['Test R2']\n",
    "        \n",
    "        print(f\"  - 剩余特征数: {X_train_ablated.shape[1]}\")\n",
    "        print(f\"  - 训练集 R²: {ablated_metrics['Train R2']:.4f}\")\n",
    "        print(f\"  - 测试集 R²: {ablated_metrics['Test R2']:.4f}\")\n",
    "        print(f\"  - 与基准相比 R² 变化: {r2_change:.4f}\")\n",
    "\n",
    "        # 记录结果\n",
    "        results.append({\n",
    "            'Removed_Feature': feature,\n",
    "            'Remaining_Features': X_train_ablated.shape[1],\n",
    "            'Train_R2': ablated_metrics['Train R2'],\n",
    "            'Test_R2': ablated_metrics['Test R2'],\n",
    "            'R2_Change_From_Base': r2_change\n",
    "        })\n",
    "\n",
    "    # 4. 汇总并保存结果\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"消融分析结果汇总\")\n",
    "    print(\"=\"*60)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    # 保存详细结果到CSV文件\n",
    "    results_df.to_csv(os.path.join(output_dir, \"ablation_analysis_results.csv\"), index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n详细结果已保存至: {os.path.join(output_dir, 'ablation_analysis_results.csv')}\")\n",
    "\n",
    "    # 打印关键发现\n",
    "    print(\"\\n--- 关键发现 ---\")\n",
    "    # 找出对测试集性能影响最大的特征（R² 下降最多）\n",
    "    worst_removal = results_df.iloc[1:]['R2_Change_From_Base'].idxmin()\n",
    "    best_removal = results_df.iloc[1:]['R2_Change_From_Base'].idxmax()\n",
    "    \n",
    "    print(f\"1. 移除后性能下降最显著的特征: '{results_df.loc[worst_removal, 'Removed_Feature']}'\")\n",
    "    print(f\"   - R² 变化: {results_df.loc[worst_removal, 'R2_Change_From_Base']:.4f}\")\n",
    "    print(f\"   - 该特征对模型性能至关重要。\")\n",
    "\n",
    "    print(f\"\\n2. 移除后性能下降最少（或提升）的特征: '{results_df.loc[best_removal, 'Removed_Feature']}'\")\n",
    "    print(f\"   - R² 变化: {results_df.loc[best_removal, 'R2_Change_From_Base']:.4f}\")\n",
    "    print(f\"   - 该特征可能是冗余的，或其信息可被其他特征替代。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c91dc0-0ab3-4fe9-8c41-64275f7041b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "开始执行EN.与NOₓ转化率单调正相关统计显著性完整分析\n",
      "================================================================================\n",
      "输出目录已创建/确认：EN_statistical_complete_analysis\n",
      "原始数据总量：242，去除缺失值后：242\n",
      "目标区间（0.74-0.78）样本量：80\n",
      "输出目录已创建/确认：EN_statistical_complete_analysis\n",
      "综合分析图已保存：EN_statistical_complete_analysis\\EN._comprehensive_analysis.png\n",
      "输出目录已创建/确认：EN_statistical_complete_analysis\n",
      "详细统计报告已保存：EN_statistical_complete_analysis\\EN._statistical_report.txt\n",
      "输出目录已创建/确认：EN_statistical_complete_analysis\n",
      "目标区间数据表格已保存：EN_statistical_complete_analysis\\EN._target_range_data.xlsx\n",
      "\n",
      "================================================================================\n",
      "核心结果摘要：\n",
      "================================================================================\n",
      "分析区间：EN. ∈ [0.74, 0.78]\n",
      "样本量：80个\n",
      "Spearman相关系数：0.3776，p值：0.000554\n",
      "Kendall τ系数：0.275，p值：0.000518\n",
      "统计显著性结论：显著单调正相关\n",
      "================================================================================\n",
      "分析完成！所有结果已保存至：EN_statistical_complete_analysis\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import spearmanr, kendalltau, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# ==================== 核心参数配置 ====================\n",
    "# 数据和输出路径\n",
    "input_path = \"归一化数据-20251120.xlsx\"\n",
    "output_dir = \"EN_statistical_complete_analysis\"\n",
    "model_path = \"xgboost_model_ncv/xgboost_model.pkl\"\n",
    "\n",
    "# 关键列名定义\n",
    "target_column = \"SO2 tolerance\"\n",
    "feature_column = \"EN.\"\n",
    "en_range = (0.74, 0.78)\n",
    "\n",
    "# 图表样式配置\n",
    "figsize = (14, 10)\n",
    "title_font = {'family': 'Arial', 'size': 24, 'weight': 'bold'}\n",
    "label_font = {'family': 'Arial', 'size': 24, 'weight': 'bold'}\n",
    "tick_font = {'family': 'Arial', 'size': 22, 'weight': 'bold'}\n",
    "legend_font = {'family': 'Arial', 'size': 22, 'weight': 'bold'}\n",
    "\n",
    "# 颜色配置\n",
    "scatter_color = '#2E86AB'\n",
    "trend_line_color = '#A23B72'\n",
    "\n",
    "# 线条样式\n",
    "line_width = 3\n",
    "scatter_size = 80\n",
    "border_width = 2\n",
    "tick_width = 2\n",
    "tick_length = 6\n",
    "dpi = 600\n",
    "\n",
    "# ==================== 工具函数定义 ====================\n",
    "def create_output_dir():\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    print(f\"输出目录已创建/确认：{output_dir}\")\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"输入数据文件不存在：{input_path}\")\n",
    "    df = pd.read_excel(input_path)\n",
    "    \n",
    "    required_cols = [target_column, feature_column]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"数据文件缺失必要列：{', '.join(missing_cols)}\")\n",
    "    \n",
    "    df_clean = df.dropna(subset=required_cols).copy()\n",
    "    print(f\"原始数据总量：{len(df)}，去除缺失值后：{len(df_clean)}\")\n",
    "    \n",
    "    df_target = df_clean[\n",
    "        (df_clean[feature_column] >= en_range[0]) & \n",
    "        (df_clean[feature_column] <= en_range[1])\n",
    "    ].copy()\n",
    "    \n",
    "    if len(df_target) < 5:\n",
    "        raise Warning(f\"目标区间样本量较少（{len(df_target)}个），统计结果需谨慎解读\")\n",
    "    elif len(df_target) < 3:\n",
    "        raise ValueError(f\"目标区间样本量不足（仅{len(df_target)}个），无法进行有效统计检验\")\n",
    "    \n",
    "    print(f\"目标区间（{en_range[0]}-{en_range[1]}）样本量：{len(df_target)}\")\n",
    "    return df_clean, df_target\n",
    "\n",
    "def statistical_tests(df_target):\n",
    "    x = df_target[feature_column].values\n",
    "    y = df_target[target_column].values\n",
    "    \n",
    "    spearman_r, spearman_p = spearmanr(x, y)\n",
    "    kendall_tau, kendall_p = kendalltau(x, y)\n",
    "    pearson_r, pearson_p = pearsonr(x, y)\n",
    "    \n",
    "    slope, intercept, r_value, p_value_reg, std_err = stats.linregress(x, y)\n",
    "    \n",
    "    conf_int = stats.t.interval(\n",
    "        0.95, len(x)-2, loc=slope, scale=std_err\n",
    "    )\n",
    "    \n",
    "    results = {\n",
    "        \"样本量\": len(df_target),\n",
    "        \"EN.区间\": f\"{en_range[0]}-{en_range[1]}\",\n",
    "        \"Spearman相关系数(r)\": round(spearman_r, 4),\n",
    "        \"Spearman p值\": round(spearman_p, 6),\n",
    "        \"Kendall τ系数\": round(kendall_tau, 4),\n",
    "        \"Kendall p值\": round(kendall_p, 6),\n",
    "        \"Pearson相关系数(r)\": round(pearson_r, 4),\n",
    "        \"Pearson p值\": round(pearson_p, 6),\n",
    "        \"线性回归斜率\": round(slope, 4),\n",
    "        \"斜率p值\": round(p_value_reg, 6),\n",
    "        \"斜率95%置信区间\": (round(conf_int[0], 4), round(conf_int[1], 4)),\n",
    "        \"R²（决定系数）\": round(r_value**2, 4),\n",
    "        \"统计显著性结论\": \"显著单调正相关\" if (spearman_p < 0.05 and spearman_r > 0) else \"不显著\"\n",
    "    }\n",
    "    \n",
    "    return results, x, y\n",
    "\n",
    "def plot_comprehensive_analysis(x, y, results):\n",
    "    create_output_dir()\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white')\n",
    "    \n",
    "    # 绘制散点图\n",
    "    ax.scatter(x, y, color=scatter_color, s=scatter_size, alpha=0.8, \n",
    "               edgecolors='black', linewidth=1.5, label='Original Data')\n",
    "    \n",
    "    # 绘制趋势线\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_trend = np.linspace(en_range[0], en_range[1], 100)\n",
    "    ax.plot(x_trend, p(x_trend), color=trend_line_color, linewidth=line_width, \n",
    "            alpha=0.9, label=f'Trend Line (r={results[\"Spearman相关系数(r)\"]:.3f})')\n",
    "    \n",
    "    # 设置坐标轴范围\n",
    "    ax.set_xlim(en_range[0]-0.01, en_range[1]+0.01)\n",
    "    ax.set_ylim(y.min()-0.05, y.max()+0.05)\n",
    "    \n",
    "    # 设置标题\n",
    "    title_text = f'{feature_column} vs NOₓ Conversion (0.74-0.78 Interval)\\n' \\\n",
    "                 f'Spearman p={results[\"Spearman p值\"]:.6f}, Kendall p={results[\"Kendall p值\"]:.6f}'\n",
    "    ax.set_title(title_text, fontdict=title_font, pad=25)\n",
    "    ax.set_xlabel(f'{feature_column} ', fontdict=label_font, labelpad=15)\n",
    "    ax.set_ylabel('NOₓ Conversion', fontdict=label_font, labelpad=15)\n",
    "    \n",
    "    # 设置刻度样式\n",
    "    ax.tick_params(axis='both', which='major', width=tick_width, length=tick_length, \n",
    "                   labelsize=tick_font['size'])\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontproperties(tick_font)\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(tick_font)\n",
    "    \n",
    "    # 设置边框样式\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(border_width)\n",
    "        spine.set_color('black')\n",
    "    \n",
    "    # 设置图例\n",
    "    ax.legend(prop=legend_font, frameon=False, loc='upper left', bbox_to_anchor=(0.02, 0.98))\n",
    "    \n",
    "    # 添加网格\n",
    "    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.8)\n",
    "    \n",
    "    # 保存图片\n",
    "    save_path = os.path.join(output_dir, f\"{feature_column}_comprehensive_analysis.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    print(f\"综合分析图已保存：{save_path}\")\n",
    "\n",
    "def save_statistical_report(results):\n",
    "    create_output_dir()\n",
    "    report_path = os.path.join(output_dir, f\"{feature_column}_statistical_report.txt\")\n",
    "    \n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"EN.与NOₓ转化率单调正相关统计显著性分析报告\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"1. 分析基础信息\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(f\"数据文件：{input_path}\\n\")\n",
    "        f.write(f\"分析区间：EN. ∈ [{en_range[0]}, {en_range[1]}]\\n\")\n",
    "        f.write(f\"目标变量：{target_column}（NOₓ转化率）\\n\")\n",
    "        f.write(f\"分析样本量：{results['样本量']}个\\n\\n\")\n",
    "        \n",
    "        f.write(\"2. 核心统计检验结果\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(f\"Spearman秩相关系数 (r)：{results['Spearman相关系数(r)']}\\n\")\n",
    "        f.write(f\"Spearman p值：{results['Spearman p值']} {'(显著)' if results['Spearman p值'] < 0.05 else '(不显著)'}\\n\")\n",
    "        f.write(f\"Kendall τ系数：{results['Kendall τ系数']}\\n\")\n",
    "        f.write(f\"Kendall p值：{results['Kendall p值']} {'(显著)' if results['Kendall p值'] < 0.05 else '(不显著)'}\\n\")\n",
    "        f.write(f\"Pearson相关系数 (r)：{results['Pearson相关系数(r)']}\\n\")\n",
    "        f.write(f\"Pearson p值：{results['Pearson p值']} {'(显著)' if results['Pearson p值'] < 0.05 else '(不显著)'}\\n\\n\")\n",
    "        \n",
    "        f.write(\"3. 线性回归分析结果\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(f\"回归斜率：{results['线性回归斜率']}\\n\")\n",
    "        f.write(f\"斜率p值：{results['斜率p值']}\\n\")\n",
    "        f.write(f\"斜率95%置信区间：{results['斜率95%置信区间']}\\n\")\n",
    "        f.write(f\"决定系数 (R²)：{results['R²（决定系数）']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"4. 结论\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        if results['统计显著性结论'] == \"显著单调正相关\":\n",
    "            f.write(f\"在EN. ∈ [{en_range[0]}, {en_range[1]}]区间内，\\n\")\n",
    "            f.write(f\"EN.与NOₓ转化率呈显著单调正相关（Spearman r={results['Spearman相关系数(r)']:.4f}, p={results['Spearman p值']:.6f} < 0.05）。\\n\")\n",
    "            f.write(f\"线性回归斜率为正（{results['线性回归斜率']:.4f}），且斜率显著不为0（p={results['斜率p值']:.6f}），\\n\")\n",
    "            f.write(\"进一步验证了正相关趋势的可靠性。\")\n",
    "        else:\n",
    "            f.write(f\"在EN. ∈ [{en_range[0]}, {en_range[1]}]区间内，\\n\")\n",
    "            f.write(f\"EN.与NOₓ转化率的单调正相关不显著（Spearman p={results['Spearman p值']:.6f} ≥ 0.05），\\n\")\n",
    "            f.write(\"需扩大样本量或检查数据分布合理性。\")\n",
    "    \n",
    "    print(f\"详细统计报告已保存：{report_path}\")\n",
    "\n",
    "def save_data_table(df_target, results):\n",
    "    create_output_dir()\n",
    "    table_path = os.path.join(output_dir, f\"{feature_column}_target_range_data.xlsx\")\n",
    "    \n",
    "    df_output = df_target[[feature_column, target_column]].copy()\n",
    "    df_output.columns = [f\"{feature_column} (Normalized)\", \"NOₓ Conversion (Normalized)\"]\n",
    "    df_output = df_output.sort_values(by=f\"{feature_column} (Normalized)\").reset_index(drop=True)\n",
    "    \n",
    "    summary_row = pd.Series({\n",
    "        f\"{feature_column} (Normalized)\": \"统计摘要\",\n",
    "        \"NOₓ Conversion (Normalized)\": f\"Spearman r={results['Spearman相关系数(r)']:.4f}, p={results['Spearman p值']:.6f}\"\n",
    "    })\n",
    "    df_output = pd.concat([df_output, summary_row.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    df_output.to_excel(table_path, index=False)\n",
    "    print(f\"目标区间数据表格已保存：{table_path}\")\n",
    "\n",
    "# ==================== 主程序执行 ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"开始执行EN.与NOₓ转化率单调正相关统计显著性完整分析\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        create_output_dir()\n",
    "        \n",
    "        df_clean, df_target = load_and_preprocess_data()\n",
    "        \n",
    "        stats_results, x_data, y_data = statistical_tests(df_target)\n",
    "        \n",
    "        plot_comprehensive_analysis(x_data, y_data, stats_results)\n",
    "        \n",
    "        save_statistical_report(stats_results)\n",
    "        \n",
    "        save_data_table(df_target, stats_results)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"核心结果摘要：\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"分析区间：EN. ∈ [{en_range[0]}, {en_range[1]}]\")\n",
    "        print(f\"样本量：{stats_results['样本量']}个\")\n",
    "        print(f\"Spearman相关系数：{stats_results['Spearman相关系数(r)']}，p值：{stats_results['Spearman p值']}\")\n",
    "        print(f\"Kendall τ系数：{stats_results['Kendall τ系数']}，p值：{stats_results['Kendall p值']}\")\n",
    "        print(f\"统计显著性结论：{stats_results['统计显著性结论']}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"分析完成！所有结果已保存至：{output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n分析过程出错：{str(e)}\")\n",
    "        print(\"请检查输入文件路径、列名正确性或样本量是否充足\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87fa11-e6a3-4d19-8b8b-70a3ed2c33e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
